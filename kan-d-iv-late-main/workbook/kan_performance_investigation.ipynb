{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KAN Performance Investigation Workbook\n",
    "\n",
    "**Objective**: This workbook provides a structured environment to investigate the performance of the KAN-based D-IV-LATE estimator. It addresses two key questions:\n",
    "\n",
    "1.  **Hyperparameter Sensitivity**: Can the KAN estimator's performance (as measured by RMSE) be improved by tuning its hyperparameters?\n",
    "2.  **Uncertainty Quantification**: Can we obtain reliable confidence intervals and coverage rates for the KAN estimator using a computationally feasible bootstrap procedure?\n",
    "\n",
    "The results from this investigation will inform the final narrative of the research paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "First, we import the necessary libraries and the custom functions from our project's source code. This includes utilities for training KANs, generating data, and estimating the D-IV-LATE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- Colab Environment Setup ---\n",
    "print(\"Setting up Colab environment...\")\n",
    "\n",
    "# 1. Install the efficient-kan dependency\n",
    "print(\"Installing efficient-kan library...\")\n",
    "!pip install git+https://github.com/shawcharles/efficient-kan.git\n",
    "\n",
    "# 2. Clone the main project repository\n",
    "repo_name = 'kan-d-iv-late' # The name of the repo directory\n",
    "if not os.path.exists(repo_name):\n",
    "    print(f\"\\nCloning repository '{repo_name}'...\")\n",
    "    !git clone https://github.com/shawcharles/kan-d-iv-late.git\n",
    "else:\n",
    "    print(f\"\\nRepository '{repo_name}' already exists.\")\n",
    "\n",
    "# 3. Add the project's code directory to the Python path\n",
    "# The path structure is kan-d-iv-late/kan-d-iv-late/code\n",
    "code_path = os.path.abspath(os.path.join(repo_name, 'kan-d-iv-late', 'code'))\n",
    "if code_path not in sys.path:\n",
    "    sys.path.append(code_path)\n",
    "    print(f\"Added '{code_path}' to sys.path\")\n",
    "else:\n",
    "    print(f\"'{code_path}' is already in sys.path\")\n",
    "\n",
    "# --- End Colab Setup ---\n",
    "\n",
    "# 4. Now, import our standardized utilities and simulation functions\n",
    "print(\"\\nImports starting...\")\n",
    "import kan_utils\n",
    "from kan_d_iv_late_simulation_enhanced import (\n",
    "    generate_dlate_data,\n",
    "    estimate_nuisance_functions_enhanced,\n",
    "    dlate_estimator,\n",
    "    run_enhanced_simulation, # We will adapt its logic\n",
    "    create_enhanced_plots\n",
    ")\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "print(f\"\\nUsing device: {kan_utils.DEVICE}\")\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Part 1: Hyperparameter Tuning Analysis\n",
    "\n",
    "In this section, we conduct a grid search over a predefined set of KAN hyperparameters. For each combination, we run a fast Monte Carlo simulation (few replications, no bootstrapping) to estimate the Root Mean Squared Error (RMSE). The goal is to identify the set of hyperparameters that minimizes the RMSE.\n",
    "\n",
    "The results will be saved to `hyperparameter_tuning_results.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration for Hyperparameter Search ---\n",
    "N_REPLICATIONS_FAST = 20  # Number of MC replications for each setting (increased for more stability)\n",
    "N_SAMPLES = 1000\n",
    "Y_GRID_SIZE = 30\n",
    "\n",
    "# Define the hyperparameter grid to search\n",
    "HYPERPARAM_GRID = {\n",
    "    'KAN_STEPS': [50, 150, 250],\n",
    "    'KAN_HIDDEN_DIM': [16, 32, 48],\n",
    "    'KAN_REG_STRENGTH': [1e-3, 1e-4, 1e-5]\n",
    "}\n",
    "\n",
    "# Directory to save results\n",
    "output_dir = '../results'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "all_hyperparam_results = []\n",
    "\n",
    "print(\"Starting Hyperparameter Sensitivity Analysis...\")\n",
    "\n",
    "y_grid = np.linspace(-8, 15, Y_GRID_SIZE)\n",
    "\n",
    "# --- Main Grid Search Loop ---\n",
    "for steps in tqdm(HYPERPARAM_GRID['KAN_STEPS'], desc=\"KAN Steps\"):\n",
    "    for hidden_dim in tqdm(HYPERPARAM_GRID['KAN_HIDDEN_DIM'], desc=\"Hidden Dims\", leave=False):\n",
    "        for reg_strength in tqdm(HYPERPARAM_GRID['KAN_REG_STRENGTH'], desc=\"Reg Strength\", leave=False):\n",
    "            \n",
    "            # Temporarily override KAN settings in the imported module\n",
    "            kan_utils.KAN_STEPS = steps\n",
    "            kan_utils.KAN_HIDDEN_DIM = hidden_dim\n",
    "            kan_utils.KAN_REG_STRENGTH = reg_strength\n",
    "\n",
    "            kan_estimates = []\n",
    "            true_values = []\n",
    "\n",
    "            # Run fast simulation for this hyperparameter set\n",
    "            for rep in range(N_REPLICATIONS_FAST):\n",
    "                data, true_dlate_func = generate_dlate_data(n_samples=N_SAMPLES, seed=rep)\n",
    "                true_dlate = np.array([true_dlate_func(y) for y in y_grid])\n",
    "                true_values.append(true_dlate)\n",
    "                \n",
    "                try:\n",
    "                    nuisance_df = estimate_nuisance_functions_enhanced(data, y_grid, model_type='kan')\n",
    "                    dlate_est = dlate_estimator(data, nuisance_df, y_grid)\n",
    "                    kan_estimates.append(dlate_est)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during estimation: {e}\")\n",
    "                    kan_estimates.append(np.full(len(y_grid), np.nan))\n",
    "\n",
    "            # Calculate performance metric (mean RMSE across the y_grid)\n",
    "            kan_estimates = np.array(kan_estimates)\n",
    "            true_values = np.array(true_values)\n",
    "            mean_rmse = np.sqrt(np.nanmean((kan_estimates - true_values)**2))\n",
    "            \n",
    "            all_hyperparam_results.append({\n",
    "                'steps': steps, \n",
    "                'hidden_dim': hidden_dim, \n",
    "                'reg_strength': reg_strength, \n",
    "                'mean_rmse': mean_rmse\n",
    "            })\n",
    "\n",
    "# --- Process and Save Hyperparameter Results ---\n",
    "hyperparam_results_df = pd.DataFrame(all_hyperparam_results)\n",
    "hyperparam_results_path = os.path.join(output_dir, 'hyperparameter_tuning_results.csv')\n",
    "hyperparam_results_df.to_csv(hyperparam_results_path, index=False)\n",
    "\n",
    "print(\"\\nHyperparameter Sensitivity Analysis Complete.\")\n",
    "print(f\"Results saved to {hyperparam_results_path}\")\n",
    "\n",
    "# Find and display the best parameters\n",
    "best_params = hyperparam_results_df.loc[hyperparam_results_df['mean_rmse'].idxmin()]\n",
    "print(\"\\nBest performing hyperparameters based on Mean RMSE:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Tuning Results\n",
    "\n",
    "A heatmap can help visualize the relationship between hyperparameters and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hyperparam_results_df.empty:\n",
    "    pivot_table = hyperparam_results_df.pivot_table(\n",
    "        index=['steps', 'reg_strength'], \n",
    "        columns='hidden_dim', \n",
    "        values='mean_rmse'\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(pivot_table, annot=True, fmt=\".4f\", cmap=\"viridis_r\", linewidths=.5)\n",
    "    plt.title('Hyperparameter Grid Search Results (Mean RMSE)')\n",
    "    plt.ylabel('Training Steps & Regularization Strength')\n",
    "    plt.xlabel('Hidden Dimension')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No results to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Part 2: Limited Bootstrap Analysis\n",
    "\n",
    "Using the best hyperparameters identified in Part 1, we now run a more intensive simulation. This run uses a moderate number of Monte Carlo replications and enables bootstrapping to calculate 95% confidence intervals for the D-IV-LATE estimates. \n",
    "\n",
    "The primary goal is to assess the **empirical coverage** of the bootstrap CIs. Good coverage (close to 95%) would indicate that the bootstrap provides a reliable method for uncertainty quantification for the KAN estimator.\n",
    "\n",
    "The detailed results of this analysis will be saved to `bootstrap_analysis_results.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration for Bootstrap Analysis ---\n",
    "N_REPLICATIONS_BOOTSTRAP = 30  # A reasonable number for a limited analysis\n",
    "N_BOOTSTRAP_SAMPLES = 199      # Odd number to avoid ties, standard for bootstrap CIs\n",
    "\n",
    "# --- Set Best Hyperparameters from Part 1 ---\n",
    "if 'best_params' in locals():\n",
    "    print(f\"Using best parameters from tuning: \\n{best_params}\")\n",
    "    kan_utils.KAN_STEPS = int(best_params['steps'])\n",
    "    kan_utils.KAN_HIDDEN_DIM = int(best_params['hidden_dim'])\n",
    "    kan_utils.KAN_REG_STRENGTH = float(best_params['reg_strength'])\n",
    "else:\n",
    "    print(\"Warning: Best parameters not found. Using default KAN settings.\")\n",
    "\n",
    "print(\"\\nStarting Limited Bootstrap Analysis...\")\n",
    "\n",
    "# --- Run Simulation with Bootstrap Enabled ---\n",
    "# This logic is adapted from the run_enhanced_simulation script\n",
    "\n",
    "y_grid = np.linspace(-8, 15, Y_GRID_SIZE)\n",
    "results_storage = {'kan': [], 'rf': []}\n",
    "true_values_list = []\n",
    "\n",
    "for rep in tqdm(range(N_REPLICATIONS_BOOTSTRAP), desc=\"Bootstrap MC Replications\"):\n",
    "    data, true_dlate_func = generate_dlate_data(n_samples=N_SAMPLES, seed=rep)\n",
    "    true_dlate = np.array([true_dlate_func(y) for y in y_grid])\n",
    "    true_values_list.append(true_dlate)\n",
    "    \n",
    "    for model_type in ['kan', 'rf']:\n",
    "        try:\n",
    "            # The bootstrap_dlate_ci function handles the full estimation loop\n",
    "            dlate_results = kan_utils.bootstrap_dlate_ci(\n",
    "                data, y_grid,\n",
    "                nuisance_estimator=lambda d, y: estimate_nuisance_functions_enhanced(d, y, model_type=model_type),\n",
    "                dlate_estimator=dlate_estimator,\n",
    "                n_bootstrap=N_BOOTSTRAP_SAMPLES\n",
    "            )\n",
    "            results_storage[model_type].append(dlate_results)\n",
    "        except Exception as e:\n",
    "            print(f\"{model_type.upper()} estimation failed in replication {rep}: {e}\")\n",
    "            # Append NaNs if estimation fails\n",
    "            nan_results = {\n",
    "                'point_estimates': np.full(len(y_grid), np.nan),\n",
    "                'ci_lower': np.full(len(y_grid), np.nan),\n",
    "                'ci_upper': np.full(len(y_grid), np.nan)\n",
    "            }\n",
    "            results_storage[model_type].append(nan_results)\n",
    "\n",
    "print(\"Bootstrap analysis complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Process and Save Bootstrap Results ---\n",
    "true_values = np.array(true_values_list)\n",
    "\n",
    "results_df = pd.DataFrame({'y_value': y_grid, 'true_dlate': np.mean(true_values, axis=0)})\n",
    "\n",
    "for model_type, storage in results_storage.items():\n",
    "    estimates = np.array([r['point_estimates'] for r in storage])\n",
    "    ci_lower = np.array([r['ci_lower'] for r in storage])\n",
    "    ci_upper = np.array([r['ci_upper'] for r in storage])\n",
    "    \n",
    "    # Performance metrics\n",
    "    results_df[f'{model_type}_estimate'] = np.nanmean(estimates, axis=0)\n",
    "    results_df[f'{model_type}_bias'] = np.nanmean(estimates - true_values, axis=0)\n",
    "    results_df[f'{model_type}_rmse'] = np.sqrt(np.nanmean((estimates - true_values)**2, axis=0))\n",
    "    \n",
    "    # Confidence interval coverage\n",
    "    coverage = np.mean((true_values >= ci_lower) & (true_values <= ci_upper), axis=0)\n",
    "    results_df[f'{model_type}_coverage'] = coverage\n",
    "    results_df[f'{model_type}_ci_width'] = np.nanmean(ci_upper - ci_lower, axis=0)\n",
    "\n",
    "bootstrap_results_path = os.path.join(output_dir, 'bootstrap_analysis_results.csv')\n",
    "results_df.to_csv(bootstrap_results_path, index=False)\n",
    "\n",
    "print(f\"Bootstrap analysis results saved to {bootstrap_results_path}\")\n",
    "print(\"\\n--- Results Summary ---\")\n",
    "print(results_df[['y_value', 'kan_rmse', 'rf_rmse', 'kan_coverage', 'rf_coverage']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Bootstrap Results\n",
    "\n",
    "We can now plot the key metrics from the bootstrap analysis: RMSE and, most importantly, empirical coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Bootstrap Analysis Results (Best KAN vs. RF)', fontsize=16)\n",
    "\n",
    "# Plot 1: RMSE Comparison\n",
    "ax = axes[0]\n",
    "ax.plot(results_df['y_value'], results_df['kan_rmse'], 'r-', linewidth=2, label='KAN RMSE')\n",
    "ax.plot(results_df['y_value'], results_df['rf_rmse'], 'b-', linewidth=2, label='RF RMSE')\n",
    "ax.set_xlabel('y')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Root Mean Squared Error (RMSE)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.4)\n",
    "\n",
    "# Plot 2: Coverage Comparison\n",
    "ax = axes[1]\n",
    "ax.plot(results_df['y_value'], results_df['kan_coverage'], 'r-', linewidth=2, label='KAN Coverage')\n",
    "ax.plot(results_df['y_value'], results_df['rf_coverage'], 'b-', linewidth=2, label='RF Coverage')\n",
    "ax.axhline(y=0.95, color='k', linestyle='--', alpha=0.7, label='Nominal 95% Level')\n",
    "ax.set_xlabel('y')\n",
    "ax.set_ylabel('Empirical Coverage')\n",
    "ax.set_title('95% Bootstrap Confidence Interval Coverage')\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.4)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Print average coverage\n",
    "avg_kan_coverage = results_df['kan_coverage'].mean()\n",
    "avg_rf_coverage = results_df['rf_coverage'].mean()\n",
    "print(f\"Average KAN Coverage: {avg_kan_coverage:.3f}\")\n",
    "print(f\"Average RF Coverage:  {avg_rf_coverage:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion and Next Steps\n",
    "\n",
    "Based on the results from the hyperparameter tuning and the bootstrap analysis, we can now make an informed decision on how to proceed with the paper.\n",
    "\n",
    "**Scenario A: KAN is Salvageable**\n",
    "- If the tuned KAN estimator shows RMSE that is competitive with or better than the Random Forest.\n",
    "- AND if the bootstrap confidence intervals for the KAN estimator show good empirical coverage (close to 0.95).\n",
    "- **Recommendation**: Proceed with one final, large-scale computation using the optimal KAN hyperparameters and bootstrap CIs. The paper's narrative will be about the power of KANs when carefully tuned and paired with robust inference methods.\n",
    "\n",
    "**Scenario B: KAN is Not Superior in this Context**\n",
    "- If the KAN estimator's RMSE remains significantly worse than the Random Forest, even after tuning.\n",
    "- OR if the bootstrap CIs for KAN have poor coverage, indicating unreliable uncertainty estimates.\n",
    "- **Recommendation**: Pivot the paper's narrative to a \"caveat emptor\" story. The key finding becomes a cautionary tale about the challenges of applying new, complex models. This requires no further large-scale computation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
