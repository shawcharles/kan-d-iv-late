# -*- coding: utf-8 -*-
"""kan_simulation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xvlihVPS8DiTUVOV_l_nBSrF6Itl4Luu
"""

#!pip install pykan

"""# Main"""

import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
# from kan import KAN # Old import
from efficient_kan import KAN # New import
import torch
import torch.nn as nn # For loss functions
import torch.optim as optim # For optimizers

import sys # For is_running_in_colab
import os # For zip_and_download_results_colab
import shutil # For zip_and_download_results_colab

# Determine if running in Colab once at module level
_is_actually_in_colab = 'google.colab' in sys.modules

def is_running_in_colab():
    """Checks if the script is running in a Google Colab environment."""
    return _is_actually_in_colab

# KAN training parameters (globally accessible within this script)
KAN_STEPS = 25
KAN_LR = 1e-3
KAN_WEIGHT_DECAY = 1e-4 # For AdamW
KAN_REG_STRENGTH = 1e-4 # Multiplier for model.regularization_loss()
KAN_HIDDEN_DIM = 16 # Hidden layer size for KANs
MIN_CLASS_COUNT_THRESHOLD = 5 # For skipping KAN fit due to imbalance

# Helper function for training efficient_kan models
def train_efficient_kan_model(model, train_input, train_label, steps, lr, weight_decay, reg_strength, device_str='cpu'):
    # Determine device
    # device = torch.device("cuda" if torch.cuda.is_available() else "cpu") # This should be handled outside if model is already on device
    # model.to(device) # Ensure model is on the right device
    # train_input = train_input.to(device)
    # train_label = train_label.to(device)

    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)
    criterion = nn.BCEWithLogitsLoss() # Use BCEWithLogitsLoss for binary classification

    for step in range(steps):
        model.train()
        optimizer.zero_grad()
        output_logits = model(train_input)
        
        # Ensure output_logits and train_label have compatible shapes
        if output_logits.shape != train_label.shape:
             # This can happen if train_label is (batch,) and output_logits is (batch, 1)
             # Or if KAN outputs extra dimensions for some reason.
             # For BCEWithLogitsLoss, they should match.
             # If train_label is (batch_size,) and output_logits is (batch_size, 1),
             # then train_label might need to be unsqueezed or output_logits squeezed.
             # Given KAN output is likely (batch,1) and label is (batch,1), this should be fine.
             # However, if KAN output is (batch,) it needs unsqueeze(1)
             if output_logits.ndim == 1: # If KAN output is (batch_size)
                 output_logits = output_logits.unsqueeze(1)


        loss_c = criterion(output_logits, train_label)
        loss_r = model.regularization_loss()
        total_loss = loss_c + reg_strength * loss_r
        
        total_loss.backward()
        optimizer.step()

        # if (step + 1) % (steps // 5 if steps >=5 else 1) == 0: # Optional: print progress
        #     print(f"  Step {step+1}/{steps}, Total Loss: {total_loss.item():.4f}, Crit Loss: {loss_c.item():.4f}, Reg Loss: {loss_r.item():.4f}")
    # print(f"  Final Loss after {steps} steps: {total_loss.item():.4f}")

# --- 1. Data Generating Process (DGP) ---
def generate_dlate_data(n_samples=2000, n_features=5, seed=42):
    """
    Generates a dataset with a known D-LATE and complex non-linearities.
    """
    np.random.seed(seed)

    # Generate covariates
    X = np.random.randn(n_samples, n_features)

    # Nuisance functions
    pi_x = torch.sigmoid(torch.tensor(X[:, 0] + np.sin(np.pi * X[:, 1]) - np.cos(np.pi * X[:, 2]) + 0.5 * X[:, 3]**2 - 0.5 * X[:, 4]**2)).numpy()
    Z = np.random.binomial(1, pi_x)

    p_zx = torch.sigmoid(torch.tensor(Z + X[:, 0] + np.sin(np.pi * X[:, 1]) - np.cos(np.pi * X[:, 2]) + 0.5 * X[:, 3]**2 - 0.5 * X[:, 4]**2)).numpy()
    W = np.random.binomial(1, p_zx)

    # Potential outcomes
    Y0 = X[:, 0] + np.sin(np.pi * X[:, 1]) + np.random.randn(n_samples)
    Y1 = Y0 + 10 + np.cos(np.pi * X[:, 2]) + np.random.randn(n_samples)

    # Observed outcome
    Y = W * Y1 + (1 - W) * Y0

    data = pd.DataFrame(X, columns=[f'X{i}' for i in range(n_features)])
    data['Z'] = Z
    data['W'] = W
    data['Y'] = Y

    # True D-LATE for compliers (in this DGP, all are compliers)
    true_dlate_func = lambda y: np.mean(Y1 <= y) - np.mean(Y0 <= y)

    return data, true_dlate_func

# --- 2. Nuisance Function Estimators ---
def estimate_nuisance_functions(data, y_grid, model_type='kan', k_folds=3): # Reduced k_folds
    """
    Estimates the three nuisance functions using K-fold cross-fitting.
    """
    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)

    # KAN training parameters are now global: KAN_STEPS, KAN_LR, etc.

    mu_hat = np.zeros((len(data), len(y_grid)))
    p_hat = np.zeros(len(data))
    pi_hat = np.zeros(len(data))

    X_cols = [col for col in data.columns if col.startswith('X')]
    n_features_X = len(X_cols)

    for fold_idx, (train_index, test_index) in enumerate(kf.split(data)):
        data_train, data_test = data.iloc[train_index], data.iloc[test_index]

        if model_type == 'kan':
            # Estimate pi(x) = P(Z=1 | X)
            pi_model = KAN(layers_hidden=[n_features_X, KAN_HIDDEN_DIM, 1], grid_size=4, spline_order=3)
            # Convert data to tensors
            pi_train_input = torch.from_numpy(data_train[X_cols].values).float()
            pi_train_label = torch.from_numpy(data_train['Z'].values).float().unsqueeze(1)
            train_efficient_kan_model(pi_model, pi_train_input, pi_train_label, steps=KAN_STEPS, lr=KAN_LR, weight_decay=KAN_WEIGHT_DECAY, reg_strength=KAN_REG_STRENGTH)
            with torch.no_grad():
                pi_hat[test_index] = torch.sigmoid(pi_model(torch.from_numpy(data_test[X_cols].values).float())).detach().numpy().flatten()

            # Estimate p(z, x) = P(W=1 | Z, X)
            p_model = KAN(layers_hidden=[n_features_X + 1, KAN_HIDDEN_DIM, 1], grid_size=4, spline_order=3)
            p_train_input = torch.from_numpy(data_train[X_cols + ['Z']].values).float()
            p_train_label = torch.from_numpy(data_train['W'].values).float().unsqueeze(1)
            train_efficient_kan_model(p_model, p_train_input, p_train_label, steps=KAN_STEPS, lr=KAN_LR, weight_decay=KAN_WEIGHT_DECAY, reg_strength=KAN_REG_STRENGTH)
            with torch.no_grad():
                p_hat[test_index] = torch.sigmoid(p_model(torch.from_numpy(data_test[X_cols + ['Z']].values).float())).detach().numpy().flatten()

            # Estimate mu(y, w, x) = E[1{Y<=y} | W, X]
            for i, y_val in enumerate(y_grid):
                data_train_y = data_train.copy()
                data_train_y['Y_le_y'] = (data_train_y['Y'] <= y_val).astype(int)
                mu_model = KAN(layers_hidden=[n_features_X + 1, KAN_HIDDEN_DIM, 1], grid_size=4, spline_order=3)

                # --- Start Diagnostic Prints ---
                print(f"--- Debug: Fold {fold_idx + 1}/{kf.get_n_splits()}, y_grid index {i}, y_val: {y_val} ---")
                train_input_np = data_train_y[X_cols + ['W']].values
                train_label_np = data_train_y['Y_le_y'].values
                test_input_np = data_test[X_cols + ['W']].values
                test_label_np = (data_test['Y'] <= y_val).astype(int).values

                print(f"Train Input: shape={train_input_np.shape}, NaNs={np.isnan(train_input_np).any()}, Infs={np.isinf(train_input_np).any()}, min={np.min(train_input_np) if train_input_np.size > 0 else 'N/A'}, max={np.max(train_input_np) if train_input_np.size > 0 else 'N/A'}, mean={np.mean(train_input_np) if train_input_np.size > 0 else 'N/A'}")
                print(f"Train Label: shape={train_label_np.shape}, NaNs={np.isnan(train_label_np).any()}, unique_counts={np.unique(train_label_np, return_counts=True)}")
                print(f"Test Input: shape={test_input_np.shape}, NaNs={np.isnan(test_input_np).any()}, Infs={np.isinf(test_input_np).any()}, min={np.min(test_input_np) if test_input_np.size > 0 else 'N/A'}, max={np.max(test_input_np) if test_input_np.size > 0 else 'N/A'}, mean={np.mean(test_input_np) if test_input_np.size > 0 else 'N/A'}")
                print(f"Test Label: shape={test_label_np.shape}, NaNs={np.isnan(test_label_np).any()}, unique_counts={np.unique(test_label_np, return_counts=True)}")
                # --- End Diagnostic Prints ---

                # --- Start Enhanced Diagnostics ---
                if train_input_np.size > 0 and train_input_np.shape[1] > 0:
                    print("Train Input Feature Details (for mu_model):")
                    # Correlation Matrix
                    try:
                        # Ensure no NaNs/Infs before corrcoef if not already checked by previous diagnostics
                        if not (np.isnan(train_input_np).any() or np.isinf(train_input_np).any()):
                            corr_matrix = np.corrcoef(train_input_np, rowvar=False)
                            print(f"  Train Input Correlation Matrix (first 5x5 if large, for features {X_cols + ['W']}):\n{corr_matrix[:5, :5]}")
                            if np.isnan(corr_matrix).any() or np.isinf(corr_matrix).any():
                                print("    WARNING: NaNs or Infs in correlation matrix!")
                        else:
                            print("  Skipping correlation matrix due to NaNs/Infs in input (already reported).")
                    except Exception as e:
                        print(f"  Could not compute correlation matrix: {e}")

                    # Unique values and variance per feature
                    feature_names_for_mu_model = X_cols + ['W']
                    for col_idx in range(train_input_np.shape[1]):
                        feature_name = feature_names_for_mu_model[col_idx] if col_idx < len(feature_names_for_mu_model) else f"Feature_{col_idx}"
                        col_data = train_input_np[:, col_idx]
                        unique_vals = np.unique(col_data)
                        variance = np.var(col_data)
                        print(f"    Feature '{feature_name}': Unique values count={len(unique_vals)}, Variance={variance:.4e}")
                        if len(unique_vals) == 1:
                            print(f"      WARNING: Feature '{feature_name}' is constant with value {unique_vals[0]}")
                        if variance < 1e-9: # Threshold for very low variance
                            print(f"      WARNING: Feature '{feature_name}' has very low variance: {variance:.4e}")
                else:
                    print("  Train Input for mu_model is empty or has no features, skipping enhanced diagnostics.")
                # --- End Enhanced Diagnostics ---

                # Refined check for unfittable labels (extreme imbalance or constant)
                # min_class_count_threshold is now global: MIN_CLASS_COUNT_THRESHOLD
                unique_labels, counts = np.unique(train_label_np, return_counts=True)

                if len(unique_labels) == 1:
                    constant_val = unique_labels[0]
                    print(f"Skipping KAN fit for y_val={y_val} due to constant train label: {constant_val}. Setting mu_hat to constant.")
                    mu_hat[test_index, i] = constant_val
                elif len(unique_labels) > 1 and np.min(counts) < MIN_CLASS_COUNT_THRESHOLD:
                    majority_class_val = unique_labels[np.argmax(counts)]
                    print(f"Skipping KAN fit for y_val={y_val} due to extreme class imbalance (minority count: {np.min(counts)} < {MIN_CLASS_COUNT_THRESHOLD}). Setting mu_hat to majority class: {majority_class_val}.")
                    mu_hat[test_index, i] = float(majority_class_val) # Ensure it's float for mu_hat array
                else:
                    print(f"Proceeding with KAN fit for y_val={y_val}.")
                    # --- Original Diagnostic Print (End) ---
                    print(f"--- End Debug ---")
                    mu_train_input = torch.from_numpy(data_train_y[X_cols + ['W']].values).float()
                    mu_train_label = torch.from_numpy(data_train_y['Y_le_y'].values).float().unsqueeze(1)
                    train_efficient_kan_model(mu_model, mu_train_input, mu_train_label, steps=KAN_STEPS, lr=KAN_LR, weight_decay=KAN_WEIGHT_DECAY, reg_strength=KAN_REG_STRENGTH)
                    with torch.no_grad():
                        mu_hat[test_index, i] = torch.sigmoid(mu_model(torch.from_numpy(data_test[X_cols + ['W']].values).float())).detach().numpy().flatten()

        elif model_type == 'rf':
            # Estimate pi(x) = P(Z=1 | X)
            # Add check for RF if labels are constant to avoid IndexError
            if len(np.unique(data_train['Z'])) == 1:
                # If Z is constant in a fold, pi_hat will be that constant (0 or 1)
                # This will cause division by zero later. Set to a clipped value.
                # Or, better, this fold might be problematic for the estimator.
                # For now, let's set to the constant, and clipping will handle it.
                pi_hat_fold_val = np.unique(data_train['Z'])[0]
                pi_hat[test_index] = pi_hat_fold_val 
            else:
                pi_model_rf = RandomForestClassifier(n_estimators=100, random_state=42)
                pi_model_rf.fit(data_train[X_cols], data_train['Z'])
                pi_hat[test_index] = pi_model_rf.predict_proba(data_test[X_cols])[:, 1]
            
            # Clipping pi_hat for the current fold's test_index
            epsilon = 1e-6
            pi_hat[test_index] = np.clip(pi_hat[test_index], epsilon, 1 - epsilon)

            # Estimate p(z, x) = P(W=1 | Z, X)
            if len(np.unique(data_train['W'])) == 1:
                p_hat_fold_val = np.unique(data_train['W'])[0]
                p_hat[test_index] = p_hat_fold_val
            else:
                p_model_rf = RandomForestClassifier(n_estimators=100, random_state=42)
                p_model_rf.fit(data_train[X_cols + ['Z']], data_train['W'])
                p_hat[test_index] = p_model_rf.predict_proba(data_test[X_cols + ['Z']])[:, 1]
            
            # Clipping p_hat for the current fold's test_index
            p_hat[test_index] = np.clip(p_hat[test_index], epsilon, 1 - epsilon)
            
            # The following two blocks for pi_model and p_model were duplicated. Removing them.
            # pi_model = RandomForestClassifier(n_estimators=100, random_state=42)
            # pi_model.fit(data_train[X_cols], data_train['Z'])
            # pi_hat[test_index] = pi_model.predict_proba(data_test[X_cols])[:, 1]

            # # Estimate p(z, x) = P(W=1 | Z, X)
            # p_model = RandomForestClassifier(n_estimators=100, random_state=42)
            # p_model.fit(data_train[X_cols + ['Z']], data_train['W'])
            # p_hat[test_index] = p_model.predict_proba(data_test[X_cols + ['Z']])[:, 1]

            # Estimate mu(y, w, x) = E[1{Y<=y} | W, X]
            for i, y_val in enumerate(y_grid):
                data_train_y = data_train.copy()
                data_train_y['Y_le_y'] = (data_train_y['Y'] <= y_val).astype(int)
                
                # Add check for RF if labels for mu_model are constant/imbalanced
                rf_unique_labels, rf_counts = np.unique(data_train_y['Y_le_y'], return_counts=True)
                if len(rf_unique_labels) == 1:
                    mu_hat[test_index, i] = rf_unique_labels[0]
                # elif len(rf_unique_labels) > 1 and np.min(rf_counts) < 2: # Stricter for RF if needed, or rely on RF's robustness
                #    mu_hat[test_index, i] = float(rf_unique_labels[np.argmax(rf_counts)])
                else:
                    mu_model_rf = RandomForestClassifier(n_estimators=100, random_state=42)
                    mu_model_rf.fit(data_train_y[X_cols + ['W']], data_train_y['Y_le_y'])
                    # Handle potential IndexError if predict_proba returns single column
                    try:
                        mu_hat[test_index, i] = mu_model_rf.predict_proba(data_test[X_cols + ['W']])[:, 1]
                    except IndexError:
                        # This happens if RF predicts only one class for all test samples in this fold
                        # Predict the majority class from training or a default
                        print(f"IndexError in RF predict_proba for y_val={y_val}. Defaulting mu_hat for this fold.")
                        # Check what RF would predict if forced (e.g. predict directly)
                        # Or, more simply, use the majority class from training for this fold
                        majority_class_val_rf = rf_unique_labels[np.argmax(rf_counts)]
                        mu_hat[test_index, i] = float(majority_class_val_rf)


    nuisance_df = pd.DataFrame({'pi_hat': pi_hat, 'p_hat': p_hat})
    for i, y_val in enumerate(y_grid):
        nuisance_df[f'mu_hat_{y_val}'] = mu_hat[:, i]

    return nuisance_df

# --- 3. D-LATE Estimator ---
def dlate_estimator(data, nuisance_df, y_grid):
    X_cols = [col for col in data.columns if col.startswith('X')]
    Z = data['Z'].values
    W = data['W'].values
    Y = data['Y'].values
    pi_hat = nuisance_df['pi_hat'].values
    p_hat = nuisance_df['p_hat'].values

    psi_beta = (Z - pi_hat) / (pi_hat * (1 - pi_hat)) * (W - p_hat)

    dlate_estimates = []
    for i, y_val in enumerate(y_grid):
        mu_hat_y = nuisance_df[f'mu_hat_{y_val}'].values

        # Estimate mu(y, 1, x) and mu(y, 0, x) using cross-fitting
        kf = KFold(n_splits=3, shuffle=True, random_state=42) # Reduced k_folds
        mu_hat_1 = np.zeros(len(data))
        mu_hat_0 = np.zeros(len(data))

        for train_index, test_index in kf.split(data):
            data_train, data_test = data.iloc[train_index], data.iloc[test_index]

            # mu(y, 1, x)
            data_train_1 = data_train[data_train['W'] == 1]
            model1 = KAN(layers_hidden=[len(X_cols), KAN_HIDDEN_DIM, 1], grid_size=4, spline_order=3) 
            data_test_1_X_for_train = data_test[data_test['W'] == 1] 

            if not data_train_1.empty:
                m1_train_input = torch.from_numpy(data_train_1[X_cols].values).float()
                m1_train_label = (torch.from_numpy(data_train_1['Y'].values) <= y_val).float().unsqueeze(1)
                m1_unique_labels, m1_counts = np.unique(m1_train_label.numpy(), return_counts=True)
                if len(m1_unique_labels) == 1:
                    # Predict constant for all test samples in this fold for this W arm
                    for idx_in_fold, original_idx in enumerate(test_index):
                        if data.iloc[original_idx]['W'] == 1 : # Apply only to W=1 arm
                             mu_hat_1[original_idx] = m1_unique_labels[0]
                        # else leave as zero, will be filled by model0 or remain if W not in test_index for this arm
                elif len(m1_unique_labels) > 1 and np.min(m1_counts) < MIN_CLASS_COUNT_THRESHOLD: 
                    majority_val_m1 = float(m1_unique_labels[np.argmax(m1_counts)])
                    for idx_in_fold, original_idx in enumerate(test_index):
                        if data.iloc[original_idx]['W'] == 1 :
                             mu_hat_1[original_idx] = majority_val_m1
                else:
                    train_efficient_kan_model(model1, m1_train_input, m1_train_label, steps=KAN_STEPS, lr=KAN_LR, weight_decay=KAN_WEIGHT_DECAY, reg_strength=KAN_REG_STRENGTH) 
                    with torch.no_grad():
                        # Predict only for W=1 in the test set for this fold
                        test_data_w1_indices = data_test[data_test['W'] == 1].index
                        if not test_data_w1_indices.empty:
                             predictions_w1 = torch.sigmoid(model1(torch.from_numpy(data_test.loc[test_data_w1_indices, X_cols].values).float())).detach().numpy().flatten()
                             for k_idx, original_data_idx in enumerate(test_data_w1_indices):
                                 # Find where original_data_idx matches in the global test_index for this fold
                                 # This is complex because test_index is relative to the full 'data'
                                 # Simpler: mu_hat_1 is full length, so use original_data_idx directly if it's in test_index
                                 if original_data_idx in test_index: # Should always be true by construction of data_test
                                     mu_hat_1[original_data_idx] = predictions_w1[k_idx] # Assign to correct global index position
            # For test samples not in W=1 (i.e. W=0), mu_hat_1 should remain 0 or be handled by mu_hat_0
            # Defaulting remaining mu_hat_1 for this fold to 0.5 if not W=1 (or if data_train_1 was empty)
            # This part needs careful thought: mu_hat_1 is for P(Y<=y|X, W=1). If W=0, this is not directly estimated by model1.
            # The current structure of psi_alpha uses mu_hat_y which is E[1{Y<=y} | W, X] (from estimate_nuisance)
            # and alpha_hat_i = mu_hat_1 - mu_hat_0.
            # So, mu_hat_1 should be predictions for W=1, and mu_hat_0 for W=0.
            # If a test sample has W=0, its contribution to mu_hat_1 should effectively be zero or handled such that alpha_hat_i is correct.
            # The current structure of assigning to mu_hat_1[test_index] might be okay if test_index is correctly used.
            # Let's ensure that if data_train_1 is empty, mu_hat_1 for W=1 in test set gets a default.
            if data_train_1.empty:
                for original_idx in test_index:
                    if data.iloc[original_idx]['W'] == 1:
                        mu_hat_1[original_idx] = 0.5


            # mu(y, 0, x)
            data_train_0 = data_train[data_train['W'] == 0]
            model0 = KAN(layers_hidden=[len(X_cols), KAN_HIDDEN_DIM, 1], grid_size=4, spline_order=3) 
            data_test_0_X_for_train = data_test[data_test['W'] == 0] 

            if not data_train_0.empty:
                m0_train_input = torch.from_numpy(data_train_0[X_cols].values).float()
                m0_train_label = (torch.from_numpy(data_train_0['Y'].values) <= y_val).float().unsqueeze(1)
                m0_unique_labels, m0_counts = np.unique(m0_train_label.numpy(), return_counts=True)
                if len(m0_unique_labels) == 1:
                    for idx_in_fold, original_idx in enumerate(test_index):
                        if data.iloc[original_idx]['W'] == 0 :
                             mu_hat_0[original_idx] = m0_unique_labels[0]
                elif len(m0_unique_labels) > 1 and np.min(m0_counts) < MIN_CLASS_COUNT_THRESHOLD: 
                    majority_val_m0 = float(m0_unique_labels[np.argmax(m0_counts)])
                    for idx_in_fold, original_idx in enumerate(test_index):
                        if data.iloc[original_idx]['W'] == 0 :
                             mu_hat_0[original_idx] = majority_val_m0
                else:
                    train_efficient_kan_model(model0, m0_train_input, m0_train_label, steps=KAN_STEPS, lr=KAN_LR, weight_decay=KAN_WEIGHT_DECAY, reg_strength=KAN_REG_STRENGTH) 
                    with torch.no_grad():
                        test_data_w0_indices = data_test[data_test['W'] == 0].index
                        if not test_data_w0_indices.empty:
                            predictions_w0 = torch.sigmoid(model0(torch.from_numpy(data_test.loc[test_data_w0_indices, X_cols].values).float())).detach().numpy().flatten()
                            for k_idx, original_data_idx in enumerate(test_data_w0_indices):
                                if original_data_idx in test_index:
                                    mu_hat_0[original_data_idx] = predictions_w0[k_idx]
            if data_train_0.empty:
                 for original_idx in test_index:
                    if data.iloc[original_idx]['W'] == 0:
                        mu_hat_0[original_idx] = 0.5

        alpha_hat_i = mu_hat_1 - mu_hat_0
        psi_alpha = (Z - pi_hat) / (pi_hat * (1 - pi_hat)) * ((Y <= y_val).astype(int) - mu_hat_y) + alpha_hat_i
        dlate_y = np.mean(psi_alpha) / np.mean(psi_beta)
        dlate_estimates.append(dlate_y)

    return np.array(dlate_estimates)

# --- 4. Simulation Loop ---
def run_simulation(n_simulations=50, n_samples=2000, model_type='kan'):
    all_results = []
    for i in range(n_simulations):
        print(f"Running simulation {i+1}/{n_simulations} for {model_type}...")
        data, true_dlate_func = generate_dlate_data(n_samples=n_samples, seed=i)
        y_grid = np.linspace(data['Y'].min(), data['Y'].max(), 10) # Reduced y_grid points
        nuisance_df = estimate_nuisance_functions(data, y_grid, model_type=model_type)
        dlate_est = dlate_estimator(data, nuisance_df, y_grid)
        true_dlate = np.array([true_dlate_func(y) for y in y_grid])
        results = pd.DataFrame({'y': y_grid, 'dlate_est': dlate_est, 'true_dlate': true_dlate, 'bias': dlate_est - true_dlate})
        all_results.append(results)
    return pd.concat(all_results)

# --- 5. Main Execution Block ---
if __name__ == "__main__":
    print("Starting simulation study...")

    # KAN
    kan_results = run_simulation(n_simulations=50, n_samples=2000, model_type='kan')
    kan_avg_bias = kan_results.groupby('y')['bias'].mean()
    kan_rmse = np.sqrt(kan_results.groupby('y')['bias'].apply(lambda x: np.mean(x**2)))

    # Random Forest
    rf_results = run_simulation(n_simulations=50, n_samples=2000, model_type='rf')
    rf_avg_bias = rf_results.groupby('y')['bias'].mean()
    rf_rmse = np.sqrt(rf_results.groupby('y')['bias'].apply(lambda x: np.mean(x**2)))

    print("\n--- KAN Simulation Results ---")
    print("Average Bias across simulations:")
    print(kan_avg_bias)
    print("\nRMSE across simulations:")
    print(kan_rmse)

    print("\n--- Random Forest Simulation Results ---")
    print("Average Bias across simulations:")
    print(rf_avg_bias)
    print("\nRMSE across simulations:")
    print(rf_rmse)

    results_df = pd.DataFrame({
        'y': kan_avg_bias.index,
        'kan_avg_bias': kan_avg_bias.values,
        'kan_rmse': kan_rmse.values,
        'rf_avg_bias': rf_avg_bias.values,
        'rf_rmse': rf_rmse.values
    })
    results_df.to_csv('simulation_results.csv', index=False)
    print("\nResults saved to simulation_results.csv")

    # Attempt to zip and download results if in Colab
    # You can add other files or directories to this list if needed.
    # For example, if you save plots to a 'plots' directory: files_to_include_in_zip = ['simulation_results.csv', 'plots/']
    files_to_include_in_zip = ['simulation_results.csv']
    if is_running_in_colab(): # zip_and_download only if in colab
        zip_and_download_results_colab(files_to_include_in_zip)
    
    if is_running_in_colab():
        notif() # Play notification sound if in Colab

    print("\n--- End of Simulation ---")

# Colab utility functions defined here, before __main__ block
# is_running_in_colab and _is_actually_in_colab are already defined at the very top.

if _is_actually_in_colab: # Use the globally defined check from the top
    from google.colab import output, files # This import should be here

    def notif():
        """Plays a notification sound in Colab."""
        output.eval_js('new Audio("https://notificationsounds.com/message-tones/appointed-529/download/mp3").play()')

    def zip_and_download_results_colab(files_to_zip, zip_filename="simulation_results.zip"):
        """
        Zips specified files/directories and initiates download in Google Colab.
        Excludes 'sample_data' directory by default if zipping a directory.
        """
        valid_files_to_zip = [f for f in files_to_zip if os.path.exists(f)]
        if not valid_files_to_zip:
            print(f"No valid files found to zip from the list: {files_to_zip}. Download skipped.")
            return

        temp_zip_dir = "temp_zip_contents_for_download" 
        final_zip_path = os.path.abspath(zip_filename) 

        try:
            if os.path.exists(temp_zip_dir):
                shutil.rmtree(temp_zip_dir) 
            os.makedirs(temp_zip_dir)

            for item_path in valid_files_to_zip:
                if os.path.isfile(item_path):
                    shutil.copy(item_path, os.path.join(temp_zip_dir, os.path.basename(item_path)))
                elif os.path.isdir(item_path):
                    destination_dir_in_zip = os.path.join(temp_zip_dir, os.path.basename(item_path))
                    shutil.copytree(item_path, destination_dir_in_zip, 
                                    ignore=shutil.ignore_patterns('sample_data')) 
                else:
                    print(f"Warning: Path {item_path} is neither a file nor a directory. Skipping.")
            
            archive_base_name = os.path.splitext(final_zip_path)[0] 
            shutil.make_archive(archive_base_name, 'zip', root_dir=os.getcwd(), base_dir=temp_zip_dir)
            actual_zip_file_created = archive_base_name + '.zip'

            if os.path.exists(actual_zip_file_created):
                print(f"Results zipped to {actual_zip_file_created}. Attempting download...")
                files.download(actual_zip_file_created)
                print(f"Download of {actual_zip_file_created} initiated.")
            else:
                print(f"Error: Zip file {actual_zip_file_created} not found after archiving.")

        except Exception as e:
            print(f"Error during zipping or download: {e}")
        finally:
            if os.path.exists(actual_zip_file_created): # Use actual_zip_file_created for removal
                try:
                    os.remove(actual_zip_file_created)
                except Exception as e:
                    print(f"Error removing zip file: {e}")
            if os.path.exists(temp_zip_dir):
                try:
                    shutil.rmtree(temp_zip_dir)
                except Exception as e:
                    print(f"Error removing temp directory: {e}")
